{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.utils.video_visualizer import VideoVisualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.utils.visualizer import ColorMode\n",
    "from detectron2.evaluation import COCOEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'C:/Users/user/Desktop/RCP/ClimbAssistant/data'\n",
    "output_dir = os.path.join(data_path, 'output_cosine')\n",
    "filename = '7.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = cv2.imread(f'C:/Users/user/Desktop/RCP/ClimbAssistant/data/colour_check/{filename}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary to store BGR values for each colour\n",
    "colour_values = {\"YELLOW\": (0,255,255), \"GREEN\": (0,255,0), \"BLUE\": (255,0,0), \"RED\": (0,0,255), \"BLACK\": (0,0,0), \"WHITE\": (255,255,255)}\n",
    "\n",
    "configs = {'classes': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settle the model configs\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml\"))\n",
    "cfg.OUTPUT_DIR = output_dir\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set a custom testing threshold\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = configs['classes']\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get outputs from the Mask RCNN model\n",
    "outputs = predictor(frame)\n",
    "# create a HSV frame to do colour categorization\n",
    "hsv_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test colour on actual wall\n",
    "# Output a image with HSV value of each hold for checking\n",
    "def classifyHoldsTest(outputs, hsv_frame, colour_values):   \n",
    "    colour_list = []\n",
    "    contours = []\n",
    "\n",
    "    output_frame = cv2.cvtColor(hsv_frame, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    for pred_mask in outputs['instances'].pred_masks:\n",
    "        mask = pred_mask.cpu().numpy().astype('uint8') # extract mask from predictions\n",
    "\n",
    "        # Extract the contour of each predicted mask and save it in a list\n",
    "        contour, _ = cv2.findContours(mask, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "        # get top of contour\n",
    "        top = tuple(contour[0][contour[0][:, :, 1].argmin()][0])\n",
    "        contours.append(contour[0])\n",
    "\n",
    "        hsv_mean = cv2.mean(hsv_frame, mask=mask) # calculate mean HSV values of each mask\n",
    "        hsv_mean = tuple([int(x) for x in hsv_mean])\n",
    "    \n",
    "        # get hue and value\n",
    "        # hue is between 0 and 180, value is between 0 and 255\n",
    "        hue = hsv_mean[0]\n",
    "        saturation = hsv_mean[1]\n",
    "        value = hsv_mean[2]\n",
    "\n",
    "        # make use of hue to categorize colours\n",
    "        color = \"Undefined\"\n",
    "        if hue < 28:\n",
    "            color = \"YELLOW\"\n",
    "        elif hue < 78:\n",
    "            color = \"GREEN\"\n",
    "        elif hue < 120:\n",
    "            color = \"BLUE\"\n",
    "        else:\n",
    "            color = \"RED\"\n",
    "        \n",
    "        # however, value is used to determine black and white, and hue is not useful\n",
    "        # hence we reset the color if any of the holds are too dark or light as they should be classified as black and white respectively\n",
    "        if value < 48:\n",
    "            color = \"BLACK\"\n",
    "        elif saturation < 65 and value > 133:\n",
    "            color = \"WHITE\" \n",
    "\n",
    "        colour_list.append(color)\n",
    "        cv2.putText(output_frame, str(hsv_mean), org=top, fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1.5, color=colour_values[color], \n",
    "        thickness=3)\n",
    "\n",
    "\n",
    "    cv2.imwrite(os.path.join(\"C:/Users/user/Desktop/RCP/ClimbAssistant/data/colour_test\", filename), output_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifyHoldsTest(outputs, hsv_frame, colour_values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
