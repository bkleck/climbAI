{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monotone frequency implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import numpy as np\n",
    "p = pyaudio.PyAudio()\n",
    "SAMPLING_FREQ = 44100  # sampling rate, Hz, must be integer\n",
    "DURATION = 3  # in seconds, may be float\n",
    "CHANNELS = 2\n",
    "FORMAT = pyaudio.paFloat32\n",
    "stream = p.open(format=FORMAT,\n",
    "                channels=CHANNELS,\n",
    "                rate=SAMPLING_FREQ,\n",
    "                output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write2stream(fs, duration, stream, part, relative_dist, VOL_SCALE=5/50, MAX_RELATIVE_DIST=4, NEAR_RELATIVE_DIST=0.3, MAX_FREQ=800, MIN_FREQ=400):\n",
    "\n",
    "    if not relative_dist:\n",
    "        samples = np.zeros(CHANNELS * DURATION)\n",
    "    \n",
    "    else:\n",
    "        side = part[0] # l or r\n",
    "        mask = [side == \"l\", side == \"r\"] * int((fs*duration)) # generate mask to fire 1 channel, clear other\n",
    "\n",
    "        if relative_dist < NEAR_RELATIVE_DIST:\n",
    "            freq = 1200 # TODO: refine `correct` signal\n",
    "        else:\n",
    "            freq = MAX_FREQ - (relative_dist / MAX_RELATIVE_DIST) * (MAX_FREQ - MIN_FREQ)\n",
    "\n",
    "        time_samples = np.arange(fs * 2*duration) * freq / fs\n",
    "        samples = (np.sin(2 * np.pi * time_samples*mask)).astype(np.float32)\n",
    "        samples *= VOL_SCALE\n",
    "\n",
    "    output_bytes = samples.tobytes()\n",
    "    \n",
    "    with wave.open(\"test.wav\", \"wb\") as wf:\n",
    "        wf.setnchannels(CHANNELS)\n",
    "        wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "        wf.setframerate(SAMPLING_FREQ)\n",
    "        wf.writeframes(output_bytes)\n",
    "    stream.write(output_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "write2stream(fs=SAMPLING_FREQ, duration=DURATION, stream=stream, part=\"l_foot\", relative_dist=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Freq implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pyaudio.PyAudio()\n",
    "FS = 44100  # sampling rate, Hz, must be integer\n",
    "CHANNELS = 2\n",
    "FORMAT = pyaudio.paFloat32\n",
    "stream = p.open(format=FORMAT,\n",
    "                channels=CHANNELS,\n",
    "                rate=FS,\n",
    "                output=True)\n",
    "\n",
    "def write2stream(part, relative_dist, stream, MAX_DIST=7, MIN_DIST=0.6, DURATION=0.1, SOUND_ARGS=(333, 450), VOL_SCALE=0.2, FS=44100):\n",
    "\n",
    "    if relative_dist != None and part != None:\n",
    "        side = part[0]\n",
    "        if relative_dist > MIN_DIST:\n",
    "            if relative_dist > MAX_DIST:\n",
    "                relative_dist = MAX_DIST\n",
    "            freq = int(SOUND_ARGS[0]/relative_dist + SOUND_ARGS[1])\n",
    "            channel_mask = [side == \"l\", side == \"r\"] * int((FS*DURATION)) # generate mask to fire 1 channel, clear other\n",
    "            time_samples = np.arange(FS * 2*DURATION) * freq / FS\n",
    "            samples = (np.sin(2 * np.pi * time_samples*channel_mask)).astype(np.float32)\n",
    "        \n",
    "        else:\n",
    "            duration = 1\n",
    "            LOW_FREQ, HIGH_FREQ = 300, 700\n",
    "            channel_mask = [side == \"l\", side == \"r\"] * int((FS*duration)) # generate mask to fire 1 channel, clear other\n",
    "            time_samples1 = np.arange(FS * 2*(1/4*duration)) * LOW_FREQ / FS\n",
    "            time_samples2 = np.arange(FS * 2*(1/4*duration)) * HIGH_FREQ / FS\n",
    "            time_samples = np.tile(np.concatenate((time_samples1, time_samples2), axis=0), 2)\n",
    "            samples = (np.sin(2 * np.pi * time_samples*channel_mask)).astype(np.float32)\n",
    "            ones = np.ones(int(0.2*len(samples)))\n",
    "            zeros = np.zeros(int(0.05*len(samples)))\n",
    "            audio_mask = np.tile(np.concatenate((ones, zeros), axis=0), 4)\n",
    "        \n",
    "        samples *= VOL_SCALE\n",
    "        output_bytes = samples.tobytes()\n",
    "        stream.write(output_bytes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m----> 2\u001b[0m     write2stream(part\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39ml_foot\u001b[39;49m\u001b[39m\"\u001b[39;49m, relative_dist\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, stream\u001b[39m=\u001b[39;49mstream)\n",
      "Cell \u001b[1;32mIn[8], line 36\u001b[0m, in \u001b[0;36mwrite2stream\u001b[1;34m(part, relative_dist, stream, MAX_DIST, MIN_DIST, DURATION, SOUND_ARGS, VOL_SCALE, FS)\u001b[0m\n\u001b[0;32m     34\u001b[0m samples \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m VOL_SCALE\n\u001b[0;32m     35\u001b[0m output_bytes \u001b[39m=\u001b[39m samples\u001b[39m.\u001b[39mtobytes()\n\u001b[1;32m---> 36\u001b[0m stream\u001b[39m.\u001b[39;49mwrite(output_bytes)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\OneDrive - Nanyang Technological University\\Documents\\ClimbAssistant\\.venv\\lib\\site-packages\\pyaudio\\__init__.py:550\u001b[0m, in \u001b[0;36mPyAudio.Stream.write\u001b[1;34m(self, frames, num_frames, exception_on_underflow)\u001b[0m\n\u001b[0;32m    547\u001b[0m     width \u001b[39m=\u001b[39m get_sample_size(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format)\n\u001b[0;32m    548\u001b[0m     num_frames \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(\u001b[39mlen\u001b[39m(frames) \u001b[39m/\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_channels \u001b[39m*\u001b[39m width))\n\u001b[1;32m--> 550\u001b[0m pa\u001b[39m.\u001b[39;49mwrite_stream(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stream, frames, num_frames,\n\u001b[0;32m    551\u001b[0m                 exception_on_underflow)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    write2stream(part=\"l_foot\", relative_dist=1, stream=stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beep(part, stream, DURATION=1, FREQ_RANGE=(300,700), VOL_SCALE=0.2, FS=44100):\n",
    "\n",
    "    side = part[0]\n",
    "    (LOW_FREQ, HIGH_FREQ) = FREQ_RANGE\n",
    "    channel_mask = [side == \"l\", side == \"r\"] * int((FS*DURATION)) # generate mask to fire 1 channel, clear other\n",
    "    time_samples1 = np.arange(FS * 2*(1/4*DURATION)) * LOW_FREQ / FS\n",
    "    time_samples2 = np.arange(FS * 2*(1/4*DURATION)) * HIGH_FREQ / FS\n",
    "    time_samples = np.tile(np.concatenate((time_samples1, time_samples2), axis=0), 2)\n",
    "    samples = (np.sin(2 * np.pi * time_samples*channel_mask)).astype(np.float32)\n",
    "    ones = np.ones(int(0.2*len(samples)))\n",
    "    zeros = np.zeros(int(0.05*len(samples)))\n",
    "    audio_mask = np.tile(np.concatenate((ones, zeros), axis=0), 4)\n",
    "    samples *= audio_mask\n",
    "        \n",
    "    samples *= VOL_SCALE\n",
    "    output_bytes = samples.tobytes()\n",
    "    stream.write(output_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "beep(part=\"r_foot\", stream=stream)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "90ac8e948bc87c8661fa6328cdcade9b78e3a049fd6132d698f359f42bb44a4b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
